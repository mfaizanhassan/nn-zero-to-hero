{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac15896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Notation of RNN\n",
    "# Playlist by @ AndrewNg https://www.youtube.com/watch?v=S7oA5C43Rbc&ab_channel=ExploreTheKnowledge\n",
    "\"\"\"\n",
    "where,\n",
    "- a(t) is the activation to be calculated at the current time step.\n",
    "- a(t-1) is the activation from the previous time step.\n",
    "- g1, g2 are the activation functions\n",
    "- Waa, Wax, ba, Wya, by are the internal weights\n",
    "- x(t) is the input at the current time step.\n",
    "- \n",
    "\n",
    "a(t) = g1(Waa @ a(t-1) + Wax @ x(t) + ba)\n",
    "yhat(t) = g2(Wya @ a(t) + by)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- dataset\n",
    "- Adding a special end of token to the end of the training set. <EOS>\n",
    "- Tokenize the dataset\n",
    "- decision to include or exclude punctuations\n",
    "- Replacing some unique words such as a specific bread of a cat in the training examples with a\n",
    "  unique token <UNK>.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data = \"A quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "aprev = None # previous activation\n",
    "at = None\n",
    "Waa = None\n",
    "Wax = None\n",
    "ba = None\n",
    "Wya = None\n",
    "by = None\n",
    "x = None\n",
    "\n",
    "at = torch.tanh(Waa @ aprev + Wax @ x + ba)\n",
    "yhat = torch.tanh(Wya @ at + by)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
